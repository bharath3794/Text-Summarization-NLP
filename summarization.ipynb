{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "toc": {
      "nav_menu": {
        "height": "263px",
        "width": "352px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXLMzokXds8T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6c913890-9b5d-410a-a6c5-55041b3cffd9"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords #provides list of english stopwords\n",
        "stop = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeAT6X7YdzXH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "569b1e12-3756-469f-81b3-d5e7bcf2bf44"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "l0CSt_ZMds8l"
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/NLP Project/reviews.csv')#,  nrows=1000)  #, nrows=100000 sep='\\t',"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CQ3eKHyds8r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "92a53852-6007-4004-aa12-5992def2bdf6"
      },
      "source": [
        "train.head() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                               Text\n",
              "0   1  ...  I have bought several of the Vitality canned d...\n",
              "1   2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2   3  ...  This is a confection that has been around a fe...\n",
              "3   4  ...  If you are looking for the secret ingredient i...\n",
              "4   5  ...  Great taffy at a great price.  There was a wid...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji-HIidnds8x"
      },
      "source": [
        "train = train[['Summary','Text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw1iSK-lds9T"
      },
      "source": [
        "train['text_lower'] = train['Text'].str.lower()\n",
        "train['text_no_punctuation'] = train['text_lower'].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQS1cq2tds9X"
      },
      "source": [
        "train['summary_lower'] = train[\"Summary\"].str.lower()\n",
        "train['summary_no_punctuation'] =  '_start_' + ' ' +train['summary_lower'].str.replace('[^\\w\\s]','')+ ' ' +'_end_'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "6VvLtdruds9b"
      },
      "source": [
        "**VERY IMPORTANT TRICK!! NOTICE THAT WE ADD \"_start_\" and \"_end_\" EXACTLY AT THE BEGINNING AND THE END OF EACH SENTENCE TO HAVE SOME KIND OF'DELIMITERS' THAT WILL TELL OUR DECODER TO START AND FINISH. BECAUSE WE DON'T HAVE GENERAL SIGNALS OF START AND FINISH IN NATURAL LANGUAGE. BASICALLY '_end_' REFLECTS THE POINT IN WHICH OUR OUTPUT SENTENCE IS MORE LIKELY TO END.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlyBo906ds9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "ea10a743-20ad-4202-cc04-32ee57c5a344"
      },
      "source": [
        "train = train.drop(columns=['Summary','Text','text_lower','summary_lower'])\n",
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_no_punctuation</th>\n",
              "      <th>summary_no_punctuation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i have bought several of the vitality canned d...</td>\n",
              "      <td>_start_ good quality dog food _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
              "      <td>_start_ not as advertised _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this is a confection that has been around a fe...</td>\n",
              "      <td>_start_ delight says it all _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>if you are looking for the secret ingredient i...</td>\n",
              "      <td>_start_ cough medicine _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great taffy at a great price  there was a wide...</td>\n",
              "      <td>_start_ great taffy _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568449</th>\n",
              "      <td>great for sesame chickenthis is a good if not ...</td>\n",
              "      <td>_start_ will not do without _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568450</th>\n",
              "      <td>im disappointed with the flavor the chocolate ...</td>\n",
              "      <td>_start_ disappointed _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568451</th>\n",
              "      <td>these stars are small so you can give 1015 of ...</td>\n",
              "      <td>_start_ perfect for our maltipoo _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568452</th>\n",
              "      <td>these are the best treats for training and rew...</td>\n",
              "      <td>_start_ favorite training and reward treat _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568453</th>\n",
              "      <td>i am very satisfied product is as advertised i...</td>\n",
              "      <td>_start_ great honey _end_</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>568454 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      text_no_punctuation                            summary_no_punctuation\n",
              "0       i have bought several of the vitality canned d...               _start_ good quality dog food _end_\n",
              "1       product arrived labeled as jumbo salted peanut...                   _start_ not as advertised _end_\n",
              "2       this is a confection that has been around a fe...                 _start_ delight says it all _end_\n",
              "3       if you are looking for the secret ingredient i...                      _start_ cough medicine _end_\n",
              "4       great taffy at a great price  there was a wide...                         _start_ great taffy _end_\n",
              "...                                                   ...                                               ...\n",
              "568449  great for sesame chickenthis is a good if not ...                 _start_ will not do without _end_\n",
              "568450  im disappointed with the flavor the chocolate ...                        _start_ disappointed _end_\n",
              "568451  these stars are small so you can give 1015 of ...            _start_ perfect for our maltipoo _end_\n",
              "568452  these are the best treats for training and rew...  _start_ favorite training and reward treat _end_\n",
              "568453  i am very satisfied product is as advertised i...                         _start_ great honey _end_\n",
              "\n",
              "[568454 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk5KcmvDds9g"
      },
      "source": [
        "max_features1 = 5000\n",
        "#maxlen1 = 30\n",
        "\n",
        "max_features2 = 5000\n",
        "#maxlen2 = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HysEdlAeds9k"
      },
      "source": [
        "#Here each word is represented with a number in the vocabulary and these numbers are used to represent the input text as an array\n",
        "tok1 = tf.keras.preprocessing.text.Tokenizer(num_words=max_features1) \n",
        "tok1.fit_on_texts(list(train['text_no_punctuation'].astype(str))) #fit to cleaned text\n",
        "tf_train_text =tok1.texts_to_sequences(list(train['text_no_punctuation'].astype(str)))\n",
        "#tf_train_text =tf.keras.preprocessing.sequence.pad_sequences(tf_train_text, maxlen=maxlen1) #let's execute pad step \n",
        "tf_train_text =tf.keras.preprocessing.sequence.pad_sequences(tf_train_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGRfBM33WjW9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "12c120c3-11d2-431e-9f55-7c48e09db29e"
      },
      "source": [
        "'''\n",
        "# Save\n",
        "np.save('/content/drive/My Drive/Colab Notebooks/1-model/tok1_word_index.npy', tok1.word_index) \n",
        "\n",
        "# Load\n",
        "tok1.word_index = np.load('/content/drive/My Drive/Colab Notebooks/1-model/tok1_word_index.npy',allow_pickle='TRUE').item()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-76cabcff5cce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtok1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tok1_word_index.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TRUE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tok1_word_index.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_1bQmDSds9s"
      },
      "source": [
        "#the processing has to be done for both \n",
        "#two different tokenizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMRQJURjds9v"
      },
      "source": [
        "#This is same step as above but we do the representation for summary\n",
        "tok2 = tf.keras.preprocessing.text.Tokenizer(num_words=max_features2, filters = '*') \n",
        "tok2.fit_on_texts(list(train['summary_no_punctuation'].astype(str))) #fit to cleaned text\n",
        "tf_train_summary = tok2.texts_to_sequences(list(train['summary_no_punctuation'].astype(str)))\n",
        "#tf_train_summary = tf.keras.preprocessing.sequence.pad_sequences(tf_train_summary, maxlen=maxlen2, padding ='post') \n",
        "tf_train_summary = tf.keras.preprocessing.sequence.pad_sequences(tf_train_summary, padding ='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idGCPfIUaOZD"
      },
      "source": [
        "'''\n",
        "# Save\n",
        "np.save('/content/drive/My Drive/Colab Notebooks/1-model/tok2_word_index.npy', tok2.word_index) \n",
        "\n",
        "# Load\n",
        "tok2.word_index = np.load('/content/drive/My Drive/Colab Notebooks/1-model/tok2_word_index.npy',allow_pickle='TRUE').item()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T8yi69lRN1K"
      },
      "source": [
        "'''\n",
        "np.save('/content/drive/My Drive/Colab Notebooks/1-model/tf_train_text.npy', tf_train_text)\n",
        "np.save('/content/drive/My Drive/Colab Notebooks/1-model/tf_train_summary.npy', tf_train_summary)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMFFuoxads91"
      },
      "source": [
        "# Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwUOS7RCds91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "201c2ae7-b494-4aa7-dbdb-00df556e17d8"
      },
      "source": [
        "vectorized_summary = tf_train_summary\n",
        "# For Decoder Input, you don't need the last word as that is only for prediction\n",
        "# when we are training using Teacher Forcing.\n",
        "decoder_input_data = vectorized_summary[:, :-1]\n",
        "\n",
        "# Decoder Target Data Is Ahead By 1 Time Step From Decoder Input Data (Teacher Forcing)\n",
        "decoder_target_data = vectorized_summary[:, 1:]\n",
        "\n",
        "print(f'Shape of decoder input: {decoder_input_data.shape}')\n",
        "print(f'Shape of decoder target: {decoder_target_data.shape}')\n",
        "\n",
        "vectorized_text = tf_train_text\n",
        "# Encoder input is simply the body of the issue text\n",
        "encoder_input_data = vectorized_text\n",
        "doc_length = encoder_input_data.shape[1]\n",
        "print(f'Shape of encoder input: {encoder_input_data.shape}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of decoder input: (568454, 39)\n",
            "Shape of decoder target: (568454, 39)\n",
            "Shape of encoder input: (568454, 2961)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Siwa8i6Qds97"
      },
      "source": [
        "vocab_size_encoder = len(tok1.word_index) + 1 #remember vocab size?\n",
        "vocab_size_decoder = len(tok2.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-ZMrt4Pds-D"
      },
      "source": [
        "### Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_TBtmwzds-D"
      },
      "source": [
        "#arbitrarly set latent dimension for embedding and hidden units\n",
        "#We previously represented word with array of numbers. But it means nothing to our model. \n",
        "#We should represent each word in a vector representation such that we can understand its meaning by finding its word embedding.\n",
        "#So we need to learn this representation that can give word embeeddings for each word. \n",
        "#This latent dimension is what your word embedding look like means each word is represented as a 300 dimensional vector\n",
        "latent_dim = 300\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUhjq8FYds-H"
      },
      "source": [
        "encoder_inputs = tf.keras.Input(shape=(doc_length,), name='Encoder-Input')\n",
        "\n",
        "# Word embeding for encoder (English text)\n",
        "x = tf.keras.layers.Embedding(vocab_size_encoder, latent_dim, name='Body-Word-Embedding', mask_zero=False)(encoder_inputs)\n",
        "\n",
        "\n",
        "#Batch normalization is used so that the distribution of the inputs \n",
        "#to a specific layer doesn't change over time\n",
        "x = tf.keras.layers.BatchNormalization(name='Encoder-Batchnorm-1')(x)\n",
        "\n",
        "\n",
        "# We do not need the `encoder_output` just the hidden state.\n",
        "_, state_h = tf.keras.layers.GRU(latent_dim, return_state=True, name='Encoder-Last-GRU')(x)\n",
        "\n",
        "# Encapsulate the encoder as a separate entity so we can just \n",
        "#  encode without decoding if we want to.\n",
        "encoder_model = tf.keras.Model(inputs=encoder_inputs, outputs=state_h, name='Encoder-Model')\n",
        "\n",
        "seq2seq_encoder_out = encoder_model(encoder_inputs)\n",
        "\n",
        "########################\n",
        "#### Decoder Model ####\n",
        "decoder_inputs = tf.keras.Input(shape=(None,), name='Decoder-Input')  # for teacher forcing\n",
        "\n",
        "# Word Embedding For Decoder\n",
        "dec_emb = tf.keras.layers.Embedding(vocab_size_decoder, latent_dim, name='Decoder-Word-Embedding', mask_zero=False)(decoder_inputs)\n",
        "#again batch normalization\n",
        "dec_bn = tf.keras.layers.BatchNormalization(name='Decoder-Batchnorm-1')(dec_emb)\n",
        "\n",
        "# Set up the decoder, using `decoder_state_input` as initial state.\n",
        "decoder_gru = tf.keras.layers.GRU(latent_dim, return_state=True, return_sequences=True, name='Decoder-GRU')\n",
        "decoder_gru_output, _ = decoder_gru(dec_bn, initial_state=seq2seq_encoder_out) #the decoder \"decodes\" the encoder output.\n",
        "x = tf.keras.layers.BatchNormalization(name='Decoder-Batchnorm-2')(decoder_gru_output)\n",
        "\n",
        "# Dense layer for prediction\n",
        "decoder_dense = tf.keras.layers.Dense(vocab_size_decoder, activation='softmax', name='Final-Output-Dense')\n",
        "decoder_outputs = decoder_dense(x)\n",
        "\n",
        "########################\n",
        "#### Seq2Seq Model ####\n",
        "seq2seq_Model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "seq2seq_Model.compile(optimizer=tf.keras.optimizers.Nadam(lr=0.001), loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZy7AesIds-K"
      },
      "source": [
        "** Examine Model Architecture Summary **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgAeAHaeds-K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "dd978368-7a96-4672-9db5-d310b3f93bda"
      },
      "source": [
        "#from seq2seq_utils import viz_model_architecture\n",
        "seq2seq_Model.summary()\n",
        "#viz_model_architecture(seq2seq_Model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Decoder-Input (InputLayer)      [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Word-Embedding (Embeddi (None, None, 300)    12858600    Decoder-Input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Input (InputLayer)      [(None, 2961)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Batchnorm-1 (BatchNorma (None, None, 300)    1200        Decoder-Word-Embedding[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Model (Model)           (None, 300)          72705000    Encoder-Input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-GRU (GRU)               [(None, None, 300),  541800      Decoder-Batchnorm-1[0][0]        \n",
            "                                                                 Encoder-Model[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Batchnorm-2 (BatchNorma (None, None, 300)    1200        Decoder-GRU[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Final-Output-Dense (Dense)      (None, None, 42862)  12901462    Decoder-Batchnorm-2[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 99,009,262\n",
            "Trainable params: 99,007,462\n",
            "Non-trainable params: 1,800\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly4q7IVZds-P"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UBkeE1Hds-Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "01ec1b9c-4200-4533-a460-dfae969a2d56"
      },
      "source": [
        "'''\n",
        "batch_size = 64\n",
        "epochs = 3 \n",
        "history = seq2seq_Model.fit([encoder_input_data, decoder_input_data], np.expand_dims(decoder_target_data, -1),\n",
        "          batch_size=batch_size,  epochs=epochs ,  validation_split=0.12) \n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nbatch_size = 64\\nepochs = 3 \\nhistory = seq2seq_Model.fit([encoder_input_data, decoder_input_data], np.expand_dims(decoder_target_data, -1),\\n          batch_size=batch_size,  epochs=epochs ,  validation_split=0.12) \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYOwuSvUds-T"
      },
      "source": [
        "# seq2seq_Model.save('Final_Model.h5')\n",
        "# seq2seq_Model.save_weights('drive/My Drive/Colab Notebooks/1-model/fulldata_final_model_weights-0.7436.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4EMzuGtds-V"
      },
      "source": [
        "#seq2seq_Model = tf.keras.models.load_model('Final_Model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-sri95jrBhF"
      },
      "source": [
        "#seq2seq_Model = tf.keras.models.load_model('Final_Model.h5')\n",
        "seq2seq_Model.load_weights('drive/My Drive/Colab Notebooks/1-model/final_model_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnQ0Jq39ECP3"
      },
      "source": [
        "test_data = train.sample(n=50000,random_state=32)\n",
        "test_samples = list(test_data['text_no_punctuation'].astype(str))\n",
        "test_targets = list(test_data['summary_no_punctuation'].astype(str))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IJ3n3XfIO3-"
      },
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/1-model/test_samples.txt', 'a+') as f:\n",
        "      for item in test_samples:\n",
        "        f.write(\"%s\\n\" % item)\n",
        "with open('/content/drive/My Drive/Colab Notebooks/1-model/test_targets.txt', 'a+') as f:\n",
        "      for item in test_targets:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h--jL0nM-NyR"
      },
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/1-model/test_samples.txt') as f:\n",
        "    test_samples = [line.rstrip() for line in f]\n",
        "with open('/content/drive/My Drive/Colab Notebooks/1-model/test_targets.txt') as f:\n",
        "    test_targets = [line.rstrip() for line in f]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixwTHAbJJCBA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "db829c97-5f77-4c9a-964e-2758dfdc5d4c"
      },
      "source": [
        "# %%time\n",
        "test_sam = test_samples[2000:3000]\n",
        "for i in range((len(test_sam)//50)+1):\n",
        "  summaries_predicted = []\n",
        "  for sample in test_sam[i*50:(i+1)*50]:\n",
        "    temp = ''\n",
        "    test_text = [sample]\n",
        "    tok1.fit_on_texts(test_text)\n",
        "    raw_tokenized = tok1.texts_to_sequences(test_text)\n",
        "    #raw_tokenized = tf.keras.preprocessing.sequence.pad_sequences(raw_tokenized, maxlen=maxlen1)\n",
        "    raw_tokenized = tf.keras.preprocessing.sequence.pad_sequences(raw_tokenized, maxlen=2961)\n",
        "    body_encoding = encoder_model.predict(raw_tokenized) #predict the encoder state of the new sentence\n",
        "    latent_dim = seq2seq_Model.get_layer('Decoder-Word-Embedding').output_shape[-1]\n",
        "    #remember the get layer methodo for getting the embedding (word clusters)\n",
        "    decoder_inputs = seq2seq_Model.get_layer('Decoder-Input').input \n",
        "    dec_emb = seq2seq_Model.get_layer('Decoder-Word-Embedding')(decoder_inputs)\n",
        "    dec_bn = seq2seq_Model.get_layer('Decoder-Batchnorm-1')(dec_emb)\n",
        "    gru_inference_state_input = tf.keras.Input(shape=(latent_dim,), name='hidden_state_input')\n",
        "    gru_out, gru_state_out = seq2seq_Model.get_layer('Decoder-GRU')([dec_bn, gru_inference_state_input])\n",
        "    # Reconstruct dense layers\n",
        "    dec_bn2 = seq2seq_Model.get_layer('Decoder-Batchnorm-2')(gru_out)\n",
        "    dense_out = seq2seq_Model.get_layer('Final-Output-Dense')(dec_bn2)\n",
        "    decoder_model = tf.keras.Model([decoder_inputs, gru_inference_state_input],\n",
        "                          [dense_out, gru_state_out])\n",
        "    # we want to save the encoder's embedding before its updated by decoder\n",
        "    #   because we can use that as an embedding for other tasks.\n",
        "    original_body_encoding = body_encoding\n",
        "    state_value = np.array(tok2.word_index['_start_']).reshape(1, 1)\n",
        "    decoded_sentence = []\n",
        "    stop_condition = False\n",
        "    vocabulary_inv = dict((v, k) for k, v in tok2.word_index.items())\n",
        "    j=0\n",
        "    while not stop_condition:\n",
        "      #print(1)\n",
        "      preds, st = decoder_model.predict([state_value, body_encoding])\n",
        "\n",
        "      pred_idx = np.argmax(preds[:, :, 2:]) + 2\n",
        "      pred_word_str = vocabulary_inv[pred_idx]\n",
        "      \n",
        "#         print(pred_word_str)\n",
        "      if pred_word_str == '_end_':\n",
        "          stop_condition = True\n",
        "          break\n",
        "      temp += pred_word_str + \" \"\n",
        "      if j>15:\n",
        "        break\n",
        "      decoded_sentence.append(pred_word_str)\n",
        "\n",
        "      # update the decoder for the next word\n",
        "      body_encoding = st\n",
        "      state_value = np.array(pred_idx).reshape(1, 1)\n",
        "      #print(state_value)\n",
        "      j+=1\n",
        "    summaries_predicted.append(temp.rstrip())\n",
        "  print(i)\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/1-model/summary_output.txt', 'a+') as f:\n",
        "    for item in summaries_predicted:\n",
        "      f.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGm5gWS5IDwG"
      },
      "source": [
        "%%time\n",
        "summaries_predicted = []\n",
        "for sample in test_samples:\n",
        "    temp = ''\n",
        "    test_text = [sample]\n",
        "    tok1.fit_on_texts(test_text)\n",
        "    raw_tokenized = tok1.texts_to_sequences(test_text)\n",
        "    #raw_tokenized = tf.keras.preprocessing.sequence.pad_sequences(raw_tokenized, maxlen=maxlen1)\n",
        "    raw_tokenized = tf.keras.preprocessing.sequence.pad_sequences(raw_tokenized, maxlen=2961)\n",
        "    body_encoding = encoder_model.predict(raw_tokenized) #predict the encoder state of the new sentence\n",
        "    latent_dim = seq2seq_Model.get_layer('Decoder-Word-Embedding').output_shape[-1]\n",
        "    #remember the get layer methodo for getting the embedding (word clusters)\n",
        "    decoder_inputs = seq2seq_Model.get_layer('Decoder-Input').input \n",
        "    dec_emb = seq2seq_Model.get_layer('Decoder-Word-Embedding')(decoder_inputs)\n",
        "    dec_bn = seq2seq_Model.get_layer('Decoder-Batchnorm-1')(dec_emb)\n",
        "    gru_inference_state_input = tf.keras.Input(shape=(latent_dim,), name='hidden_state_input')\n",
        "    gru_out, gru_state_out = seq2seq_Model.get_layer('Decoder-GRU')([dec_bn, gru_inference_state_input])\n",
        "    # Reconstruct dense layers\n",
        "    dec_bn2 = seq2seq_Model.get_layer('Decoder-Batchnorm-2')(gru_out)\n",
        "    dense_out = seq2seq_Model.get_layer('Final-Output-Dense')(dec_bn2)\n",
        "    decoder_model = tf.keras.Model([decoder_inputs, gru_inference_state_input],\n",
        "                          [dense_out, gru_state_out])\n",
        "    # we want to save the encoder's embedding before its updated by decoder\n",
        "    #   because we can use that as an embedding for other tasks.\n",
        "    original_body_encoding = body_encoding\n",
        "    state_value = np.array(tok2.word_index['_start_']).reshape(1, 1)\n",
        "    decoded_sentence = []\n",
        "    stop_condition = False\n",
        "    vocabulary_inv = dict((v, k) for k, v in tok2.word_index.items())\n",
        "    while not stop_condition:\n",
        "        #print(1)\n",
        "        preds, st = decoder_model.predict([state_value, body_encoding])\n",
        "\n",
        "        pred_idx = np.argmax(preds[:, :, 2:]) + 2\n",
        "        pred_word_str = vocabulary_inv[pred_idx]\n",
        "#         print(pred_word_str)\n",
        "        if pred_word_str == '_end_':\n",
        "            stop_condition = True\n",
        "            break\n",
        "        temp += pred_word_str + \" \"\n",
        "        decoded_sentence.append(pred_word_str)\n",
        "\n",
        "        # update the decoder for the next word\n",
        "        body_encoding = st\n",
        "        state_value = np.array(pred_idx).reshape(1, 1)\n",
        "        #print(state_value)\n",
        "    summaries_predicted.append(temp.rstrip())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RwhWnL8ds-X"
      },
      "source": [
        "sam=\"Give your Sample text here to summarize it\"\n",
        "test_text = [sam]\n",
        "tok1.fit_on_texts(test_text)\n",
        "raw_tokenized = tok1.texts_to_sequences(test_text)\n",
        "#raw_tokenized = tf.keras.preprocessing.sequence.pad_sequences(raw_tokenized, maxlen=maxlen1)\n",
        "#Here maxlen is used to make sure that the size of the sequence is same as sequence size we have while training\n",
        "raw_tokenized = tf.keras.preprocessing.sequence.pad_sequences(raw_tokenized, maxlen=len(tf_train_text[0]))\n",
        "body_encoding = encoder_model.predict(raw_tokenized) #predict the encoder state of the new sentence\n",
        "latent_dim = seq2seq_Model.get_layer('Decoder-Word-Embedding').output_shape[-1]\n",
        "#remember the get layer method for getting the embedding (word clusters)\n",
        "decoder_inputs = seq2seq_Model.get_layer('Decoder-Input').input \n",
        "dec_emb = seq2seq_Model.get_layer('Decoder-Word-Embedding')(decoder_inputs)\n",
        "dec_bn = seq2seq_Model.get_layer('Decoder-Batchnorm-1')(dec_emb)\n",
        "#GPU hidden state input\n",
        "gru_inference_state_input = tf.keras.Input(shape=(latent_dim,), name='hidden_state_input')\n",
        "#We pass it to Decoder\n",
        "gru_out, gru_state_out = seq2seq_Model.get_layer('Decoder-GRU')([dec_bn, gru_inference_state_input])\n",
        "# Reconstruct dense layers\n",
        "dec_bn2 = seq2seq_Model.get_layer('Decoder-Batchnorm-2')(gru_out)\n",
        "dense_out = seq2seq_Model.get_layer('Final-Output-Dense')(dec_bn2)\n",
        "decoder_model = tf.keras.Model([decoder_inputs, gru_inference_state_input],\n",
        "                      [dense_out, gru_state_out])\n",
        "# we want to save the encoder's embedding before its updated by decoder\n",
        "#   because we can use that as an embedding for other tasks.\n",
        "original_body_encoding = body_encoding\n",
        "state_value = np.array(tok2.word_index['_start_']).reshape(1, 1)\n",
        "decoded_sentence = []\n",
        "stop_condition = False\n",
        "vocabulary_inv = dict((v, k) for k, v in tok2.word_index.items())\n",
        "while not stop_condition:\n",
        "    #print(1)\n",
        "    preds, st = decoder_model.predict([state_value, body_encoding])\n",
        "\n",
        "    pred_idx = np.argmax(preds[:, :, 2:]) + 2\n",
        "    pred_word_str = vocabulary_inv[pred_idx]\n",
        "#         print(pred_word_str)\n",
        "    if pred_word_str == '_end_':\n",
        "        stop_condition = True\n",
        "        break\n",
        "    print(pred_word_str)\n",
        "    # temp += pred_word_str + \" \"\n",
        "    decoded_sentence.append(pred_word_str)\n",
        "\n",
        "    # update the decoder for the next word\n",
        "    body_encoding = st\n",
        "    state_value = np.array(pred_idx).reshape(1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}